{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = spark.read.text('README.md')\n",
    "textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of rows in this dataframe\n",
    "textfile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='# spark-basic')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first row of this dataframe\n",
    "textfile.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesWithSpark = textfile.filter(textfile.value.contains('spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linesWithSpark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(numWords)=12)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile.select(size(split(textfile.value, '\\s+')).name('numWords')).agg(max(col('numWords'))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts = textfile.select(explode(split(textfile.value, '\\s+')).alias('word')).groupby('word').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='`pyspark`', count=1),\n",
       " Row(word='```bash', count=2),\n",
       " Row(word='\\\\/', count=2),\n",
       " Row(word='_\\\\', count=1),\n",
       " Row(word='terminal,', count=1),\n",
       " Row(word='VM,', count=1),\n",
       " Row(word='will', count=1),\n",
       " Row(word='__/__', count=1),\n",
       " Row(word='by', count=1),\n",
       " Row(word='64-Bit', count=1),\n",
       " Row(word='more', count=1),\n",
       " Row(word='In', count=1),\n",
       " Row(word='1.8.0_131', count=1),\n",
       " Row(word='export', count=2),\n",
       " Row(word='/_/', count=1),\n",
       " Row(word='Using', count=1),\n",
       " Row(word='--help', count=1),\n",
       " Row(word='_____/', count=1),\n",
       " Row(word='for', count=1),\n",
       " Row(word='2.11.8,', count=1),\n",
       " Row(word='__/', count=1),\n",
       " Row(word='Notebook.', count=1),\n",
       " Row(word='___', count=1),\n",
       " Row(word='spark-basic', count=1),\n",
       " Row(word='_', count=2),\n",
       " Row(word='your', count=2),\n",
       " Row(word='Revision', count=1),\n",
       " Row(word='Url', count=1),\n",
       " Row(word='PYSPARK_DRIVER_PYTHON=jupyter', count=1),\n",
       " Row(word='master', count=1),\n",
       " Row(word='____', count=1),\n",
       " Row(word='file:', count=1),\n",
       " Row(word='Apache', count=1),\n",
       " Row(word='user', count=1),\n",
       " Row(word='on', count=1),\n",
       " Row(word='Installation', count=1),\n",
       " Row(word='Branch', count=1),\n",
       " Row(word='use', count=1),\n",
       " Row(word='__', count=1),\n",
       " Row(word='now', count=1),\n",
       " Row(word='`.zshrc`', count=1),\n",
       " Row(word='brew', count=1),\n",
       " Row(word='/___/', count=1),\n",
       " Row(word='.__/\\\\_,_/_/', count=1),\n",
       " Row(word='/', count=1),\n",
       " Row(word='pyspark', count=1),\n",
       " Row(word='the', count=1),\n",
       " Row(word='Version', count=1),\n",
       " Row(word='2018-02-22T19:24:29Z', count=1),\n",
       " Row(word='/__', count=1),\n",
       " Row(word='2.3.0', count=1),\n",
       " Row(word='Type', count=1),\n",
       " Row(word='tutorials', count=1),\n",
       " Row(word='sameera', count=1),\n",
       " Row(word='a0d7949896e70f427e7f3942ff340c9484ff0aab', count=1),\n",
       " Row(word='and', count=1),\n",
       " Row(word='Scala', count=1),\n",
       " Row(word='Configure', count=1),\n",
       " Row(word='HotSpot(TM)', count=1),\n",
       " Row(word='Server', count=1),\n",
       " Row(word=\"PYSPARK_DRIVER_PYTHON_OPTS='notebook'\", count=1),\n",
       " Row(word='Basic', count=1),\n",
       " Row(word='Notebook', count=1),\n",
       " Row(word='PySpark', count=1),\n",
       " Row(word='```', count=4),\n",
       " Row(word='`/', count=1),\n",
       " Row(word='#', count=1),\n",
       " Row(word='apache-spark', count=1),\n",
       " Row(word='information.', count=1),\n",
       " Row(word='install', count=1),\n",
       " Row(word='##', count=3),\n",
       " Row(word='Compiled', count=1),\n",
       " Row(word='git@github.com:sameeragarwal/spark.git', count=1),\n",
       " Row(word='`.bashrc`', count=1),\n",
       " Row(word=\"'_/\", count=1),\n",
       " Row(word='running', count=1),\n",
       " Row(word='Spark', count=1),\n",
       " Row(word='Jupyter', count=2),\n",
       " Row(word='/_/\\\\_\\\\', count=1),\n",
       " Row(word='--version', count=1),\n",
       " Row(word='', count=15),\n",
       " Row(word='$', count=2),\n",
       " Row(word='Restart', count=1),\n",
       " Row(word='Java', count=1),\n",
       " Row(word='Welcome', count=1),\n",
       " Row(word='open', count=1),\n",
       " Row(word='or', count=1),\n",
       " Row(word='to', count=2),\n",
       " Row(word='version', count=2)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
